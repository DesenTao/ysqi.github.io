<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>虞双齐Go语言技术独立咨询顾问</title>
    <link>https://yushuangqi.com/tags/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.xml</link>
    <description>在 虞双齐Go语言技术独立咨询顾问上关于的内容</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <managingEditor>devysq@gmail.com (虞双齐)</managingEditor>
    <webMaster>devysq@gmail.com (虞双齐)</webMaster>
    <atom:link href="/tags/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>用Golang写一个搜索引擎(0x02)---倒排索引技术</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x02----dao-pai-suo-yin-ji-shu.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:50 +0800</pubDate>
      <author>devysq@gmail.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x02----dao-pai-suo-yin-ji-shu.html</guid>
      <description>https://segmentfault.com/a/
这一篇，我们来说说搜索引擎最核心的技术，倒排索引技术，倒排索引可能需要分成几篇文章才说得完，我们先会说说倒排索引的技术原理，然后会讲讲怎么用一些数据结构和算法来实现一个倒排索引，然后会说一个索引器怎么通过文档来生成一个倒排索引。
倒排索引 什么是倒排索引呢？索引我们都知道，就是为了能更快的找到文档的数据结构，比如给文档编个号，那么通过这个号就可以很快的找到某一篇文档，而倒排索引不是根据文档编号，而是通过文档中的某些个词而找到文档的索引结构。
倒排索引技术简单，高效，简直是为搜索引擎这种东西量身定做的，就是靠这个技术，实现一个搜索引擎才成为可能，我们也才能在海量的文章中通过一个关键词找到我们想要的内容。
我们看个例子，有下面的几个文档：
文档编号 文档内容
1 这是一个Go语言实现的搜索引擎 2 PHP是世界上最好的语言 3 Linux是C语言和汇编语言实现的 4 谷歌是一个世界上最好的搜索引擎公司
直观的看，我们通过编号1,2,3,4可以很快的找到文档，但是我们需要通过关键词找文档，那么把上面那个表格稍微变化一下，就是倒排索引了
倒排索引【只列出了部分关键词】
关键词 文档编号
Go 1 语言 1，2，3 实现 1，3 搜索引擎 1，4 PHP 2 世界 2，4 最好 2，4 汇编 3 公司 4
这样就非常好理解了吧，实际上倒排索引就是把文档的内容切词以后重新生成了一个表格，通过这个表格，我们可以很快的找到每个关键词对应的文档，好了，没有了，到这里，就是倒排索引的核心原理，也是搜索引擎最基础的基石，不管是谷歌还是某度，最核心的东西就是这两个表格了，呵呵，没这两表格，啥都干不了。
看上去很简单吧，好吧，我们现在来模拟搜索引擎进行一次搜索，比如，我们键入关键词搜索引擎
1.我们在表格2中查到搜索引擎这个词出现在第4行
2.找到第4行的第2列，把文档编号找出来，是1和4
3.去第一个表格通过文档编号把每个文档的实际内容找出来
4.将1和4的结果显示出来
5.搜索完成
上面就是搜索引擎的最基础的技术了，如果来设计一个数据结构和算法来实现表2就成了搜索引擎技术的关键。
在实现数据结构和算法之前，我们需要知道搜索引擎搜索的是海量的数据，一般的中型电商的数据都是几十上百G的数据了，所以这个数据结构应该是存储在本地磁盘的而不是在内存中的，基于以上的考虑，为了快速搜索，要么自己实现cache来缓存热数据，要么考虑使用操作系统的底层技术MMAP，鉴于我自己实现的cache不见得（基本上是不太可能）比操作系统做得好，所以我使用的是MMAP。
MMAP系统调用  mmap是将一个文件或者其它对象映射进内存。文件被映射到多个页上，如果文件的大小不是所有页的大小之和，最后一个页不被使用的空间将会清零。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。
 mmap最大的一个好处是操作系统会自己将磁盘上的文件映射到内存，当内存足够的时候，操作文件就像操作内存一样快，而当内存不足的时候，操作系统又会自己将一些页从内存中去掉，实现了一个类似缓存的东西。特别适合于对于巨大文件的读操作，而我们的倒排索引文件就是这种巨大的文件，而且基本上写入一次以后就不太修改了，每次查询都读操作，所以使用mmap是一个比较好的选择。
mmap是一个系统调用，不同的操作系统实现有所不同，Linux下对应的C的调用方法是下面这个，具体的参数含义大家可以man一下：
 头文件 &amp;lt;sys/mman.h&amp;gt;
函数原型
void mmap(void start,size_t length,int prot,int flags,int fd,off_t offset);
 一个巨大的文件mmap之后，文件读写操作的性能由系统内存决定，系统可用内存越大，那么读写文件的性能越好，因为操作系统的内存足够，系统会将更多的文件载入到内存，提高系统吞吐量。
在Go语言中，对应的MMAP调用是：（需要引入Syscall包）
 func Mmap(fd int, offset int64, length int, prot int, flags int) (data []byte, err error)</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x03)---跳跃表哈希表</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x03----tiao-yue-biao-ha-xi-biao.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:49 +0800</pubDate>
      <author>devysq@gmail.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x03----tiao-yue-biao-ha-xi-biao.html</guid>
      <description>前面已经说了倒排索引的基本原理了，原理非常简单，也很好理解，关键是如何设计第二个倒排表，倒排表的第二列也很好设计，第一列就是关键了，为了满足快速查找的性能，设计第一列的结构，我们需要满足以下两个条件。
 查找非常快，能在极短的时间内找到我们需要的关键词所在的位置。
 添加关键词也需要比较快，能保证输入文档的时候尽可能的快。
  除了上面两个条件以外，还有一些加分项：
 如果能尽可能少的使用内存，那肯定是好的
 如果能顺序的遍历整个列，也肯定比较好
  为了满足能查找，能添加，我们首先想到的是顺序表，也就是链表了，链表的话，添加不成问题，关键是查找的复杂度是O(n)，这还能忍？所以链表第一个不考虑了。不过有一个链表的变种，我们是可以考虑一下，那就是跳跃表。
跳跃表(SkipList) 什么是跳跃表呢？跳跃表也叫跳表，我们可以把它看成是链表的一个变种，是一个多层顺序链表的并联结构的表，维基百科的定义是
 是一种随机化数据结构，基于并联的链表，其效率可比拟于二叉查找树（对于大多数操作需要O(log n)平均时间）
 我们通过一个图来看一下跳跃表(图片来源)
很明显，最底层是一个顺序表，然后在1，3，4，6，9节点上出现了第二层的链表，然后继续在1，4，6节点上面出现了第三层链表，这样构建出来的三层链表查询效率比一层的就高了，一般情况下，跳表的构建方式是按照概率来决定是否需要为这个节点增加一层，这里在层 *i* 中的元素按某个固定的概率 *p* (通常为0.5或0.25)出现在层 i+1 中。平均起来，每个元素都在 1/(1-p) 个列表中出现，而最高层的元素（通常是在跳跃列表前端的一个特殊的头元素）在 O(log1/*p* n) 个列表中出现。
查找元素的时候，起步于头元素和顶层列表，并沿着每个链表搜索，直到到达小于或着等于目标的最后一个元素。通过跟踪起自目标直到到达在更高列表中出现的元素的反向查找路径，在每个链表中预期的步数显而易见是 1/*p*。所以查找的总体代价是 O((log1/*p* n) / p)，当*p* 是常数时是 O(log n)。通过选择不同 *p* 值，就可以在查找代价和存储代价之间作出权衡。
比如还是上面那个图，我们要查找7这个元素，需要遍历1—&amp;gt;4—&amp;gt;6—&amp;gt;7，比一层链表效率高不少吧
在实现跳表的时候，虽然一般是用概率来决定是否需要增加当前节点的层级，但是实际中可以具体问题具体分析，比如我们知道底层链表大概有多长，那么我们每格10个元素增加一个层级，那么这样的跳表的存储空间我们大概也能估算出来，平均查询时间我们也能估算出来。
跳跃表是一个非常有用的数据结构，并且实现起来也比较容易，链表大家都知道实现，那么跳跃表就是一组链表啦，只是增加和删除的时候需要操作多个链表而已。
我的项目中暂时没有使用跳跃表，后续有需求的时候再加上吧，所以大家看不到代码了。让你失望了。呵呵。
一般跳跃表可以和hash配合起来使用，因为hash有桶，占用的内存较大，如果将hash值存在跳跃表中，用mmap把跳跃表加载到内存中，那么既节省了内存，又有一个较好的查询速度，而且实现起来还挺简单。
跳跃表用来实现搜索引擎的自增长类型的主键也比较合适，首先在搜索引擎中，主键的查找并不是那么频繁，一般查询都是通过关键字查询的，对主键来说，对查询速度要求并不是特别高，只有在修改主键的时候需要进行查询，其次自增长的主键一般情况下插入操作直接在链表后面append就可以了，不用进行查询，所以插入的时候也比较快。
哈希表 处理跳跃表，哈希表也是一个实现方式，哈希表是根据关键字（Key value）而直接访问在内存存储位置的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做散列函数，存放记录的数组称做哈希表，也叫散列表。
哈希是大数据技术的基础，大家应该都有了解了，这里就不深度展开了，算法导论有一章已经讲得非常清楚了，这里说说我觉得比较有意思的一个哈希的东西。
哈希表的核心是哈希算法，一个好的哈希算法可以让碰撞产生得更少，查找速度越接近于O(1)，所以一个好的哈希算法非常重要。
哈希算法很多，说都说不完，不同的算法适应不同的场景，我知道的，传说中有一个哈希算法，来自魔兽世界（！！！！为了部落！！！！），号称暴雪哈希，该算法产生的哈希值完全无法预测，被称为&amp;ldquo;One-Way Hash&amp;rdquo;( A one-way hash is a an algorithm that is constructed in such a way that deriving the original string (set of strings, actually) is virtually impossible)。</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x04)---B&amp;#43;树</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing--0x04-----b</link>
      <pubDate>Sat, 31 Dec 2016 11:33:48 +0800</pubDate>
      <author>devysq@gmail.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing--0x04-----b</guid>
      <description>本篇较长较枯燥，请保持耐心看完。
前面两章介绍了一下倒排索引以及倒排索引字典的两种存储结构，分别是跳跃表和哈希表，本篇我们介绍另一种数据结构，他也被大量使用在信息检索领域，我在github上实现的搜索引擎的词典也是用的这个数据结构，它就是B+树。
首先，我们看看什么是树，树是程序设计中一个非常基础的数据结构，记得大学时候的数据结构课，链表，栈，队列，然后就是树了，虽然那时候想必大家都被前序遍历，中序遍历，后序遍历折腾过，不过树确实是一种非常有用的数据结构。
上一篇我们说过，表2的第一列首要解决的问题就是能快速找到对应的词，然后找到对应词的倒排列表，除了跳跃表和哈希表，B+树也能满足条件，B+树是B树的变种，我们B树我们就不看了，感兴趣的大家可以直接去google一下，我们主要讲的是B+树，下图就是一个3层的B+树，我画出来可能和大家搜出来的有点出入，但是没关系，关键B+树这种数据结构的思想大家了解了就行。
假设我们有一组数字 34，40，67，5，37，12，45，24，那么，把他们存成B+树就是下图这个样子。
我们很明显看到几个特点
 每个节点的大小为2
 非叶子层的最后一个节点的最后一个元素为NULL
 最底层的叶子节点是顺序排列的，这个例子是从小到大
 上面的内节点的每一个元素都指向的下一级节点中最大的一个数相等
  我尽量的把B+树说简单点，网上的资料也好，查书也好，看上去都挺复杂的，首先我们看看怎么建立这棵树，我尽量用图了，少一些文字也好理解一点，前方大量图预警。
首先，我们的数组是34，12，5，67，37，40，45，24
第一步，初始化B+树，是这样子的 这时候，啥也没有，但是占用了两个节点，标识为无的，表示这个元素无意义，标记为NULL表示无穷大
第二步，插入34这个元素，那么图变成这样子 我们看到，插入的过程是顺着指针一直走到叶子节点，发现叶子节点是空的，然后把元素插入到叶子节点的头部，然后返回上一级节点，将NULL后移，然后把第一个元素置为他的子节点的最大值，请记住这句话：置为他的子节点的最大值
第三步，接着插入第二个元素12 这个步骤复杂一点
 从根节点开始遍历，发现12小于根节点的某一个元素【在这里是第1个元素】，顺着指针往下走
 到达叶子节点，发现12小于叶子节点的某一个元素，说明可以放在这个叶子节点中，并且叶子节点还有一个空位置，那么直接把12按大小顺序插入到这个节点中
  第四步，然后是插入5 这一步更复杂一点，产生了分裂
 从根节点开始遍历，5小于34，顺着指针往下走，到达叶子节点
 到达叶子节点，发现5小于叶子节点的某一个元素，说明可以放在这个叶子节点中，但是，这个节点已经满了，那么，分裂出一个新的节点，将5放到老节点中，被挤走的元素顺移到新节点中
 返回上一级节点，由于第一个叶子节点的最大元素已经变成12了，所以将该节点的元素由34改成指向的叶子节点的最大元素12
 由于新生成了一个节点，将NULL这个元素指向新生成的节点
  第五步，接着我们插入67 这一步比较简单
 从根节点开始遍历，67小于NULL，顺着指针往下走，到达叶子节点
 到达叶子节点，发现67大于该节点的每一个元素，并且叶子节点有空位，直接插入即可
  第六步，我们插入37，插完这个后面的我就不写了，感兴趣可以自己画一下 这一步复杂了，这一步不仅分裂了，而且分裂了两次，并且层数增加了一层
 从根节点开始遍历，37小于NULL，顺着指针往下走，到达叶子节点
 到达叶子节点，37小于叶子节点中的67，表示可以插入到这个节点中，但是节点满了，我们按照第四步的操作，分裂节点。
 分裂完了以后，产生了一个[34,37]，一个[67,无]两个节点，往上走的时候，发现上一层的节点插入了37以后也满了，继续按照第四步分裂。
 分裂完了以后，发现上层没有节点了，那么就新建一个根节点当上层节点，按照分裂的步骤给根节点赋值。
  按照这六步，前5个元素就插入到B+树中了，后面的步骤您可以自己走一走，B+树基本的思想就是这样子的，可能我没有按照教科书上的做法来说，但这并不影响大家的理解，我相信看完了以后虽然你脑子里没有标准的算法步骤，但应该有个大致的轮廓了，只不过需要自己再仔细想想步骤。
总的来说，B+树的插入步骤无外乎以下几个步骤  每次都要从根节点开始
 比较大小，找到小于当前值的元素，顺着指针往下走，继续比较大小，一直到达叶子节点，那么这个叶子节点就是你要操作的节点了。</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x06)---索引构建</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x06----suo-yin-gou-jian.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:48 +0800</pubDate>
      <author>devysq@gmail.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x06----suo-yin-gou-jian.html</guid>
      <description>https://segmentfault.com/a/
不知不觉写到第七篇了，按这个节奏，估计得写到15到20篇左右才能写完，希望自己能坚持下去，之前写代码的时候很多东西并没有想得那么细致，现在每写一篇文章还要查一些资料，确保文章的准确性，也相当于自己复习了一下吧，呵呵。
先说一下，关于倒排文件，其实还有很多东西没有讲，到后面再统一补充一下吧，主要是倒排文件的压缩技术，这一部分因为目前的存储空间不管是硬盘还是内存都是很大的，所以压缩技术用得不是很多了。
今天我们来讲讲倒排索引的构建。
之前，我们了解到了，倒排索引在系统中是存成下图这个样子
上面的B+树是一个文件，下面的倒排链是一个文件，那么，如何来构建这两个文件呢，本章我会说说一般的常规构建方法，然后说一下我是怎么构建的。
一般情况下，搜索引擎默认会认为索引是不会有太大的变化的，所以把索引分为全量索引和增量索引两部分，全量索引一般是以天甚至是周，月为单位构建的，构建完了以后就导入到引擎中进行检索，而增量索引是实时的进入搜索引擎的，很多就是保存在内存中，搜索的时候分别从全量索引和增量索引中检索数据，然后把两部分数据合并起来返回给请求方，所以增量索引不是我们这一篇的主要内容，在最后我的索引构建部分我会说一下我的增量索引构建方式。现在先看看全量索引。
全量索引构建一般有以下两种方式
一次性构建索引 一种是一次性的构建索引，这种构建方法是全量扫描所有文档，然后把所有的索引存储到内存中，直到所有文档扫描完毕，索引在内存中就构建完了，这时再一次性的写入硬盘中。大概步骤如下：
 初始化一个空map ，map的key用来保存term，map的value是一个链表，用来保存docid链
 设置docid的值为0
 读取一个文档内容，将文档编号设置成docid
 对文档进行切词操作，得到这个文档的所有term(t1,t2,t3&amp;hellip;)
 将所有的&amp;lt;term,docid&amp;gt;键值对的term插入到map的key中，docid追加到map的value中
 docid加1
 如果还有文档未读取，返回第三步，否则继续
 遍历map中的&amp;lt;key,value&amp;gt;，将value写入倒排文件中，并记录此value在文件中的偏移offset，然后将&amp;lt;key,offset&amp;gt;写入B+树中
 索引构建完毕
  用图来表示就是下面几个步骤
如果用伪代码来表示的话就是这样
//初始化ivt的map 和 docid编号 var ivt map[string][]int var docid int = 0 //依次读取文件的每一行数据 for content := range DocumentsFileContents{ terms := segmenter.Cut(content) // 切词 for _,term := range terms{ if _,ok:=ivt[term];!ok{ ivt[term]=[]int{docid} }else{ ivt[term]=append(ivt[term],docid) } docid++ } //初始化一棵B+树,字典 bt:=InitBTree(&amp;quot;.</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x07)---正排索引</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x07----zheng-pai-suo-yin.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:47 +0800</pubDate>
      <author>devysq@gmail.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x07----zheng-pai-suo-yin.html</guid>
      <description>https://segmentfault.com/a/
最近各种技术盛会太多，朋友圈各种刷屏，有厂商发的各种广告，有讲师发的各种自拍，各种参会的朋友们各种自拍，好不热闹，不知道你的朋友圈是不是也是这样啊，去年还没这么多技术会议，今年感觉爆发了，呵呵，真是一个互联网技术的好时代，而且还有各种撕B可看，真想八一八，怕得罪人，我们这种码农还是专注技术专注写代码吧。
你有什么想了解的也可以给我留言哈，欢迎交流，我的工作之前主要做的是搜索的，也做推荐和广告，这部分的东西可能写得多点，对了，嵌入式领域也行（跨得有点大，这个嵌入式不是iOS和Android，是真的嵌入式），没什么高端背景，也不是BAT这种大厂的，就是一小公司写代码的，所以有很多东西还是不懂，你要是和我交流了发现我答不上来很正常啊，人艰不拆啊。。
本篇也比较长，但是干货不多，建议上厕所的时候看，或者在地铁一边听歌一边看。
前面几篇，基本上把倒排索引的数据结构给讲完了，并且简单的说了一下排序，然后说了一下倒排索引的构建。这一篇主要写一下正排索引以及倒排和正排怎么配合起来形成一个完整的字段索引。
正排索引 正排索引，也叫前向索引，和倒排索引（也叫反向索引）是相对的，正排索引相对倒排来说简单多了，第二篇文章的时候有下面两个表格（表1和表2）
这个是表1
文档编号 文档内容
1 这是一个Go语言实现的搜索引擎 2 PHP是世界上最好的语言 3 Linux是C语言和汇编语言实现的 4 谷歌是一个世界上最好的搜索引擎公司
这个是表2
关键词 文档编号
Go 1 语言 1，2，3 实现 1，3 搜索引擎 1，4 PHP 2 世界 2，4 最好 2，4 汇编 3 公司 4
我们之前一直在说作为倒排索引的表2，对于表1，我们认为是数据的详情(detail)信息，最后用来做数据内容展示的，如果是放在一个只支持全文搜索的搜索引擎中的话，那确实表1只是用来做最后的数据展示，但是如果我们的搜索引擎还想要一些复杂的功能，那么表1就是一个正排索引，如果我们的搜索引擎同时支持倒排索引和正排索引，我们可以简单的认为这是一个数据库系统（当然，和真正的数据库还差得远啊）。
首先，我们看什么情况下要使用正排索引 很明显，如果倒排索引满足不了搜索要求的时候，就需要引入正排索引，比如一个电商的搜索引擎，那么正排索引就是必须的了，假如我们有以下几个商品需要上架：
商品编号 商品标题 发布时间 价格 品牌
10001 锤子手机T9 2026-06-06 5000 锤子 10002 小米手机10 2020-02-02 1999 小米 10003 华为手机P20 2022-12-12 3999 华为
搜索的时候我们可能需要搜索价格在一个区间的手机，那么仅仅用全文倒排索引就比较难完成任务了，而且我们在使用电商的搜索引擎的时候，经常会在搜索结果的上方看到一些汇总的信息【比如品牌，型号，价格汇总】，这一部分的东西也是通过正排索引来实现的，像下面这个图
所以说，如果我们的搜索需求不仅仅是进行关键词的匹配，还需要进行一些过滤操作（比如价格区间的过滤），汇总操作（比如结果集中每种品牌数量的统计），那么就必须引入正排索引了。
第二，我们看看如何实现一个正排索引 实现正排索引有两种方式：
一种还是基于倒排索引，之前的倒排索引不是通过B+树构建的么，B+树天然的带排序功能，所以是可以进行范围查找的，比如上面那个表格，我们要搜索的关键词为手机，价格区间在1500–4000之间。
 我们把价格字段和商品标题字段分别建立一个倒排。</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x08)---索引的段</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x08----suo-yin-de-duan.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:40 +0800</pubDate>
      <author>devysq@gmail.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x08----suo-yin-de-duan.html</guid>
      <description>https://segmentfault.com/a/
我觉得这个标题应该改改了，我写下来其实是告诉大家怎么写一个搜索引擎，并没有涉及太多的Golang的东西，我觉得这样也挺好，熟悉了原理，用什么实现其实并不重要了，而且说说原理比说代码更实在。
之前已经说了底层的数据结构了，包括倒排和正排索引。今天我们上一层，来说说索引的字段和段。
字段这个上一篇已经介绍过了，字段的概念实际上是搜索引擎索引中我们能看到的最底层的东西，也是对外暴露的最底层的概念，在字段之下是倒排和正排索引，这两项其实对用户是封装起来了，我们可以认为每个字段对应一个正排和一个倒排，而实际上也确实是这样的。
在字段之上就是我们这一篇主要说的段了，段这个概念并不是搜索引擎特有的，也不是必须的，是我这个项目新增出来的，当然，也不是我原创，很多搜索引擎的引擎系统都有这个概念。
所谓段，就是最基本的检索系统，一个段包含所有字段，包含一部分连续的文档集合，能够进行完整的检索，可以把它当成一个检索系统最基本单位。
这么说可能还是有点抽象，我们打个比方，在数据库中，一行数据是最基本的单位，对应搜索引擎中的是一个文档，而表是所有文档的集合，对应搜索引擎中是一份索引，而段就是一部分表，它包含一部分文档的内容，可以对这一部分文档进行检索，多个段合并起来就是一份完整的索引。
为什么要有段这个概念呢？  如果一个搜索引擎的数据再建好索引以后并不变化，那么完全没有必要使用段，直接在建立全量索引的时候把数据都建好就行了
 如果有增量数据，并且增量数据是不断进入系统的话，那么段的概念就有必要了，新增的数据首先在内存中进行保存，然后周期性的生成一个段，持久化到磁盘中提供检索操作。
 段还有一个好处就是当系统是一个分布式的系统的时候，进行索引同步的时候，因为各个段持久化以后就不会变化了，只需要把段拷贝到各个机器，就可以提供检索服务了，不需要在各个机器上重建索引。
 一个段损坏了，并不影响其他段的检索，只需要从其他机器上将这个段拷贝过来就能正常检索了，如果只有一个索引的话，一旦索引坏了，就无法提供检索服务了，需要等把正确索引拷贝过来才行。
  一个段都存一些什么信息呢？ 一个段包含几个文件
 indexname_{segementNumber}.meta 这里是段的元信息，包括段中字段的名称，类型，也包括段的文档的起始和终止编号。
 indexname_{segementNumber}.bt 这里是段的倒排索引的字典文件
 indexname_{segementNumber}.idx 这里是段的所有字段的倒排文件
 indexname_{segementNumber}.pfl 这里是段的所有数字正排文件的数据，同时也包含字符串类型数据的位置信息
 indexname_{segementNumber}.dtl 这里是段的字符串类型数据的详情数据
  上面的indexname是这个索引的名称，相当于数据库中的表名，segmentNumber是段编号，这个编号是系统生成的。
多个段合在一起就是一个完整的索引，检索的时候实际上是每个段单独检索，然后把数据合并起来就是最后的结果集了。
段的构建 下面我们一个一个来说说这些个文件，看看一堆正排和一堆倒排如何构成一个段的。
一个真正意义上的段的构建由以下几个步骤来构建，我们以一个实际的例子来说明一下段的构建，比如我们现在索引结构是这样，这个索引包括三个字段，分别是姓名(字符串)，年龄(数字)，自我介绍(带分词的字符串)，那么构建段和索引的时候步骤是这样的
1.前期准备 首先新建一个段需要先初始化一个段，在初始化段的时候我们实际上已经知道这个段包含哪些字段，每个字段的类型。
 初始化一个段信息，包含段所包含的字段信息和类型，在这里就是包含姓名(字符串【正排和倒排】)，年龄(数字【正排】)，自我介绍(带分词的字符串【正排和倒排】)。
 给段一个编号，比如1000。
 准备开始接收数据。
  2.建立内存中的段 内存中的段是构建段的第一步，以上述的字段信息为例，我们会在内存中建立以下几个数据结构，在这里我都是使用语言自动的原始数据结构
 姓名需要建立倒排索引，所以建立一个map&amp;lt;string,list&amp;gt;，key是姓名，value是docid，姓名也要建立正排索引，所以建立一个StringArray[]，保存每条数据的姓名的详情。
 年龄需要建立正排索引，所以建立一个IntegerArray[]，保存每条数据的年龄的详情。
 自我介绍需要建立倒排索引，所以建立一个map&amp;lt;string,list&amp;gt;，key是自我介绍的分词的term，value是docid，自我介绍也要建立正排索引，所以建立一个StringArray[]，保存每条数据的自我介绍的详情。
  当新增一条数据的时候{&amp;quot;name&amp;quot;:&amp;quot;张三&amp;quot;,&amp;quot;age&amp;quot;:18,&amp;quot;introduce&amp;quot;:&amp;quot;我喜欢跑步&amp;quot;}，首先我们给他一个docid【假如是0】，然后我们把数据分别存放到上面的5个数据结构中，如果再来一条数据{&amp;quot;name&amp;quot;:&amp;quot;李四&amp;quot;,&amp;quot;age&amp;quot;:28,&amp;quot;introduce&amp;quot;:&amp;quot;我喜欢唱歌&amp;quot;}，我们给他一个docid【假如是1】，那么数据就变成了下图的样子
3.将数据结构持久化到磁盘中 这样，随着数据的不停导入，内存中的数据结构不断变化，内存段的数据也越来越大，当达到一定阈值的时候（这部分策略以后会说，我把这部分策略放到了引擎层，由引擎来决定什么时候进行段的持久化），我们将把数据持久化到磁盘中。
进行持久化的过程中
 如果是map的数据结构，我们将遍历整个map，首先将value追加写到.idx文件中，然后把key建立B+树，value是刚刚写入的idx文件的偏移位置。
 如果是IntegerArray，我们遍历整个数组，然后把数据写入到pfl文件中，每个数据占用8个字节。</description>
    </item>
    
  </channel>
</rss>