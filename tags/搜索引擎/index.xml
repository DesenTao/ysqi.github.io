<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>虞双齐的博客</title>
    <link>https://yushuangqi.com/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E.xml</link>
    <description>在 虞双齐的博客上关于的内容</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <managingEditor>ysqi@yushuangqi.com (虞双齐)</managingEditor>
    <webMaster>ysqi@yushuangqi.com (虞双齐)</webMaster>
    <atom:link href="/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>用Golang写一个搜索引擎(0x00)---从零开始</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing--0x00----cong-ling-kai-shi.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:50 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing--0x00----cong-ling-kai-shi.html</guid>
      <description>很早就想写一系列的这样的文章了，之前在一个电商公司做搜索，对搜索引擎有一些认识，来到一个新的创业公司以后非常高兴还有机会继续做这方面的事情，虽然领域已经变了，而且不是做搜索了，但是技术还是那些技术，并且有机会接触到了Go语言，对于一个将近10年C/C++的程序员来说，Go的一些特质让我觉得非常舒服，可参见我之前的这篇文章。
从公司项目衍生出了一个自己的搜索引擎项目，然后有了这篇文章。
先聊聊目标吧，我希望实现一个这样的搜索引擎
 使用Go语言实现，方便部署，最好就用一个二进制文件搞定一些，不需要安装任何依赖。
 类似一个电商的搜索引擎，支持多字段的检索，不仅仅是文本的全文索引，还需要包括过滤功能（比如价格区间过滤），汇总功能（比如结果集中品牌数量汇总），基本的统计功能。
 索引器和搜索器在一起，主要是为了简洁，不用启多个实例。
 支持建立多个索引，并且多个索引如果有主键关联，可以进行多索引的联查（速度就只能呵呵了）。
 对于1000万的文档，单个词的平均查询时间小于10ms。
 对于一台8核8G内存的机器，QPS达到2000。
 尽可能的少用机器内存，在2G的机器上也能进行1000万以上的文档搜索。
 有较强的扩展性，可以自己扩展策略。
 可以进行分布式的集群部署，增加可搜索的文档数量，提高系统的查询吞吐量。
 支持中文分词，但分词不是我们的重点。
 支持相关性排序，但相关性排序也不是我们的重点。
 重要的一点，由于是对搜索引擎的一个全面实现，尽量不用开源的代码，所有算法和数据结构都自己实现，当然，也可以方便的进行开源替代。
  当然，一个搜索引擎涉及的部分实在是太多了，下面几个部分不是我们的重点，也不会进行深入的实现
 没有爬虫部分，搜索引擎的爬虫又是一个另外的话题了，也可以写一个很复杂的系统出来，所以我们这里不涉及爬虫的部分
 不涉及算法的部分，所谓算法部分就是排序算法，各种相关度计算，这也是一个另外的话题了，等这一系列文章结束以后再来说说排序的算法，目前仅仅有的是按照TF*IDF进行基本的相关性的基本排序
 不涉及分词部分，分词部分也是一个单独的话题，直接实现了一个非常非常非常（重要事情说三遍）简单的中文分词器（一个函数），可以用就行了。
  目前代码部分已经完成了一大半了，但是还没有进行优化，并且最后一个分布式引擎还没有完成。但是代码的核心部分，也就是搜索引擎本身的技术部分已经完成了，也已经在github上托管了，所以这一系列文章出现不更新的情况也不太可能，毕竟代码已经基本完成了。
好了，下面我们开始吧，整个系列文章将分成以下几个部分来进行描述
 一个单机的搜索引擎的架构，包括搜索引擎的模块组成，各个模块的功能已经他们之间的关系，这个部分会对搜索引擎整体有个了解，方便后面的文章的详细描述，这一部分可能会比较短，后面到第三部分会再详细说。
 搜索引擎的底层技术部分，这部分比较多的内容，会分开一个一个的讲，包括倒排索引技术，正排索引技术，分词算法，MMAP技术，这些是构成一个搜索引擎必要的底层技术，会在这一部分做介绍
 一步一步的实现一个单机的搜索引擎，按照模块从最底层的倒排和正排索引实现一直到最上层的引擎部分的实现，这一部分如果涉及到了相应的数据结构和算法也会单独写，比如哈希表算法，B+TREE算法，BitMap算法，有些我这个引擎中没有实现的算法也会一起讲讲，比如跳表，前缀树，布隆过滤器等等。
 分布式部分【TODO：需要等我代码写完了才行】，包括如何进行分布式，各个机器之间如果进行同步，索引如果进行分片
  代码已经在git上开源了，我会本周再整理一下就公布出来，目前就一堆代码实在没办法看。
好了，算是开了一个头了，文章的更新频率会在一周3到5篇左右吧，欢迎大家扫描一下下面的微信公众号订阅，首先会在这里发出来：）</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x01)---基本概念</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x01----ji-ben-gai-nian.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:50 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x01----ji-ben-gai-nian.html</guid>
      <description>从零开始，写一个搜索引擎 （0x01） 第零部分我们已经列了一个提纲了，这一篇文章开始要详细说说了。
搜索引擎基本概念 在说搜索引擎架构分层之前，我们先确定几个搜索引擎的概念。
 文档，搜索引擎的基本数据单元，比如一张网页，一个商品，多个文档合在一起就是一个搜索引擎的完整数据
 倒排索引，正排索引，存储在搜索引擎内部的数据结构，也是搜索引擎最底层的数据结构。
 索引器，将文档数据生成可供搜索的倒排索引和正排索引的程序就是索引器。
 检索器，通过对倒排索引和正排索引进行查找，从而查找到文档的程序。
 字段，每个文档可能有多个字段，比如一篇文章有标题，作者，摘要，详情，发布时间的，这些东西虽然在一个文档中，但是搜索的时候需要区别对待。
 索引，多个文档通过索引器生成了一堆倒排正排索引，我们把这些倒排正排索引的集合叫索引，如果后面提到索引就是指正排和倒排索引的集合，索引也可以理解为数据库中的表。
  好了，上面就是搜索引擎的最基本的概念，搜索引擎简单的说分成两部分，一部分就是索引器把文档变成倒排和正排文件，第二部分就是检索器通过倒排和正排文件还原文档的过程。
搜索引擎设计分层 数据库其实也是一个搜索引擎，只是数据库和搜索引擎的侧重点不太一样，搜索引擎追求的是简单，速度快，而数据库追求的是稳定和复杂逻辑对数据的处理，所以应用场景不太一样。
既然知道了一个搜索引擎的基本概念，应该怎么来设计这个搜索引擎呢？
按照一般的软件设计逻辑，如果不是非常复杂的系统，要设计一个系统，首先要设计数据结构，然后把数据结构封装到各个算法和类中，然后将各个类组合起来就完成了，所以，我设计这个引擎，是基于以下几个层次来的。
 首先需要一个底层的数据层，用来存储倒排索引和正排索引，每个字段都会建立相应的倒排和正排索引，这一部分应该有一系列相关的模块来实现；
 所有字段的倒排索引和正排索引合起来就是整个数据文件，然后需要一些模块来对这些东西进行管理；
 然后由于在第一篇文章中我们说了希望索引器和检索器都在这里，类似ElasticSearch的实现，所以也使用了分段的方式管理文档的索引，每到一定的条件下将索引刷新到磁盘或者将索引合并起来。
 我们还需要一个引擎的东西来管理多个索引，引擎负责复杂的查询策略和排序策略，这个引擎是可以更换和修改了，只需要实现标准接口就行，也可以自己实现来替换默认的引擎达到更多的功能，甚至你能自己写一个引擎，实现SQL查询。
 最后还需要一个和外界交互的层，我实现的是一个http服务器来和外部交互，交互的数据通过json来进行，这一层也可以重写成任何你需要的样子。
  按照上面这些个模块，一个搜索引擎，在整体架构上大约分成以下几个层次
 首先，最底层的是数据模块层，负责引擎内所有的数据描述，对于搜索引擎来说，数据分为倒排索引和正排索引，也叫逆向索引和正向索引，为了方便，我们这统一叫倒排索引和正排索引。
 在这一层之上是字段层，每一个字段对应了一个正排索引和一个倒排索引（可选），因为有些字段只需要展示出来而不需要进行搜索是不需要倒排的。
 在字段层之前有个段的层来对这些字段进行管理，段有的在内存中，有的刷新到磁盘上了。
 段层之上就是索引模块层了，这一层对上提供一些基本的增加，删除，修改，查找的接口。
 索引模块层之上是引擎层，这一层实现具体的业务查找逻辑。
 最上面是一个网络层，负责和外界进行交互。
  在实现的时候，为了尽量简单，每个模块基本上都是一个文件来实现的，用了Golang以后，代码写起来也自由起来了，只要清晰就行，所以整个引擎下来，代码量其实不是很大。
下面这个图就是整个代码的大框架图，后面我们会一个一个的来讲这些东西。
通过这一篇文章，希望能对搜索引擎有个初步的了解了，后面我会一个一个模块一个一个技术点的来拆分一下这个搜索引擎。
接下来的文章会开始介绍搜索引擎的底层技术了，倒排索引【会花比较多精力来说倒排索引，毕竟这是核心的核心】，正排索引【这个简单，就是数组】，在介绍的时候会有几篇文章介绍实现倒排索引技术需要的一些算法和数据结构。
代码托管在github上，地址是https://github.com/wyh267/FalconEngine，代码还在不断更新中，目前代码量，去掉单元测试文件，大约是6000行，因为是想到哪写到哪，有些函数也没有用，所以还有优化空间，也希望大家提交你的patch，后面讲的时候可以对照代码看看。
代码结构如下，再说一遍，代码量不大，结构也非常简单，虽然我写的代码注释不多，但是没有使用任何高级功能，闭包都没有，直接看没任何难度。
文章的更新频率会在一周3到5篇左右吧，欢迎大家扫描一下下面的微信公众号订阅，首先会在这里发出来：）</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x02)---倒排索引技术</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x02----dao-pai-suo-yin-ji-shu.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:50 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x02----dao-pai-suo-yin-ji-shu.html</guid>
      <description>https://segmentfault.com/a/
这一篇，我们来说说搜索引擎最核心的技术，倒排索引技术，倒排索引可能需要分成几篇文章才说得完，我们先会说说倒排索引的技术原理，然后会讲讲怎么用一些数据结构和算法来实现一个倒排索引，然后会说一个索引器怎么通过文档来生成一个倒排索引。
倒排索引 什么是倒排索引呢？索引我们都知道，就是为了能更快的找到文档的数据结构，比如给文档编个号，那么通过这个号就可以很快的找到某一篇文档，而倒排索引不是根据文档编号，而是通过文档中的某些个词而找到文档的索引结构。
倒排索引技术简单，高效，简直是为搜索引擎这种东西量身定做的，就是靠这个技术，实现一个搜索引擎才成为可能，我们也才能在海量的文章中通过一个关键词找到我们想要的内容。
我们看个例子，有下面的几个文档：
文档编号 文档内容
1 这是一个Go语言实现的搜索引擎 2 PHP是世界上最好的语言 3 Linux是C语言和汇编语言实现的 4 谷歌是一个世界上最好的搜索引擎公司
直观的看，我们通过编号1,2,3,4可以很快的找到文档，但是我们需要通过关键词找文档，那么把上面那个表格稍微变化一下，就是倒排索引了
倒排索引【只列出了部分关键词】
关键词 文档编号
Go 1 语言 1，2，3 实现 1，3 搜索引擎 1，4 PHP 2 世界 2，4 最好 2，4 汇编 3 公司 4
这样就非常好理解了吧，实际上倒排索引就是把文档的内容切词以后重新生成了一个表格，通过这个表格，我们可以很快的找到每个关键词对应的文档，好了，没有了，到这里，就是倒排索引的核心原理，也是搜索引擎最基础的基石，不管是谷歌还是某度，最核心的东西就是这两个表格了，呵呵，没这两表格，啥都干不了。
看上去很简单吧，好吧，我们现在来模拟搜索引擎进行一次搜索，比如，我们键入关键词搜索引擎
1.我们在表格2中查到搜索引擎这个词出现在第4行
2.找到第4行的第2列，把文档编号找出来，是1和4
3.去第一个表格通过文档编号把每个文档的实际内容找出来
4.将1和4的结果显示出来
5.搜索完成
上面就是搜索引擎的最基础的技术了，如果来设计一个数据结构和算法来实现表2就成了搜索引擎技术的关键。
在实现数据结构和算法之前，我们需要知道搜索引擎搜索的是海量的数据，一般的中型电商的数据都是几十上百G的数据了，所以这个数据结构应该是存储在本地磁盘的而不是在内存中的，基于以上的考虑，为了快速搜索，要么自己实现cache来缓存热数据，要么考虑使用操作系统的底层技术MMAP，鉴于我自己实现的cache不见得（基本上是不太可能）比操作系统做得好，所以我使用的是MMAP。
MMAP系统调用  mmap是将一个文件或者其它对象映射进内存。文件被映射到多个页上，如果文件的大小不是所有页的大小之和，最后一个页不被使用的空间将会清零。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。
 mmap最大的一个好处是操作系统会自己将磁盘上的文件映射到内存，当内存足够的时候，操作文件就像操作内存一样快，而当内存不足的时候，操作系统又会自己将一些页从内存中去掉，实现了一个类似缓存的东西。特别适合于对于巨大文件的读操作，而我们的倒排索引文件就是这种巨大的文件，而且基本上写入一次以后就不太修改了，每次查询都读操作，所以使用mmap是一个比较好的选择。
mmap是一个系统调用，不同的操作系统实现有所不同，Linux下对应的C的调用方法是下面这个，具体的参数含义大家可以man一下：
 头文件 &amp;lt;sys/mman.h&amp;gt;
函数原型
void mmap(void start,size_t length,int prot,int flags,int fd,off_t offset);
 一个巨大的文件mmap之后，文件读写操作的性能由系统内存决定，系统可用内存越大，那么读写文件的性能越好，因为操作系统的内存足够，系统会将更多的文件载入到内存，提高系统吞吐量。
在Go语言中，对应的MMAP调用是：（需要引入Syscall包）
 func Mmap(fd int, offset int64, length int, prot int, flags int) (data []byte, err error)</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x03)---跳跃表哈希表</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x03----tiao-yue-biao-ha-xi-biao.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:49 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x03----tiao-yue-biao-ha-xi-biao.html</guid>
      <description>前面已经说了倒排索引的基本原理了，原理非常简单，也很好理解，关键是如何设计第二个倒排表，倒排表的第二列也很好设计，第一列就是关键了，为了满足快速查找的性能，设计第一列的结构，我们需要满足以下两个条件。
 查找非常快，能在极短的时间内找到我们需要的关键词所在的位置。
 添加关键词也需要比较快，能保证输入文档的时候尽可能的快。
  除了上面两个条件以外，还有一些加分项：
 如果能尽可能少的使用内存，那肯定是好的
 如果能顺序的遍历整个列，也肯定比较好
  为了满足能查找，能添加，我们首先想到的是顺序表，也就是链表了，链表的话，添加不成问题，关键是查找的复杂度是O(n)，这还能忍？所以链表第一个不考虑了。不过有一个链表的变种，我们是可以考虑一下，那就是跳跃表。
跳跃表(SkipList) 什么是跳跃表呢？跳跃表也叫跳表，我们可以把它看成是链表的一个变种，是一个多层顺序链表的并联结构的表，维基百科的定义是
 是一种随机化数据结构，基于并联的链表，其效率可比拟于二叉查找树（对于大多数操作需要O(log n)平均时间）
 我们通过一个图来看一下跳跃表(图片来源)
很明显，最底层是一个顺序表，然后在1，3，4，6，9节点上出现了第二层的链表，然后继续在1，4，6节点上面出现了第三层链表，这样构建出来的三层链表查询效率比一层的就高了，一般情况下，跳表的构建方式是按照概率来决定是否需要为这个节点增加一层，这里在层 *i* 中的元素按某个固定的概率 *p* (通常为0.5或0.25)出现在层 i+1 中。平均起来，每个元素都在 1/(1-p) 个列表中出现，而最高层的元素（通常是在跳跃列表前端的一个特殊的头元素）在 O(log1/*p* n) 个列表中出现。
查找元素的时候，起步于头元素和顶层列表，并沿着每个链表搜索，直到到达小于或着等于目标的最后一个元素。通过跟踪起自目标直到到达在更高列表中出现的元素的反向查找路径，在每个链表中预期的步数显而易见是 1/*p*。所以查找的总体代价是 O((log1/*p* n) / p)，当*p* 是常数时是 O(log n)。通过选择不同 *p* 值，就可以在查找代价和存储代价之间作出权衡。
比如还是上面那个图，我们要查找7这个元素，需要遍历1—&amp;gt;4—&amp;gt;6—&amp;gt;7，比一层链表效率高不少吧
在实现跳表的时候，虽然一般是用概率来决定是否需要增加当前节点的层级，但是实际中可以具体问题具体分析，比如我们知道底层链表大概有多长，那么我们每格10个元素增加一个层级，那么这样的跳表的存储空间我们大概也能估算出来，平均查询时间我们也能估算出来。
跳跃表是一个非常有用的数据结构，并且实现起来也比较容易，链表大家都知道实现，那么跳跃表就是一组链表啦，只是增加和删除的时候需要操作多个链表而已。
我的项目中暂时没有使用跳跃表，后续有需求的时候再加上吧，所以大家看不到代码了。让你失望了。呵呵。
一般跳跃表可以和hash配合起来使用，因为hash有桶，占用的内存较大，如果将hash值存在跳跃表中，用mmap把跳跃表加载到内存中，那么既节省了内存，又有一个较好的查询速度，而且实现起来还挺简单。
跳跃表用来实现搜索引擎的自增长类型的主键也比较合适，首先在搜索引擎中，主键的查找并不是那么频繁，一般查询都是通过关键字查询的，对主键来说，对查询速度要求并不是特别高，只有在修改主键的时候需要进行查询，其次自增长的主键一般情况下插入操作直接在链表后面append就可以了，不用进行查询，所以插入的时候也比较快。
哈希表 处理跳跃表，哈希表也是一个实现方式，哈希表是根据关键字（Key value）而直接访问在内存存储位置的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做散列函数，存放记录的数组称做哈希表，也叫散列表。
哈希是大数据技术的基础，大家应该都有了解了，这里就不深度展开了，算法导论有一章已经讲得非常清楚了，这里说说我觉得比较有意思的一个哈希的东西。
哈希表的核心是哈希算法，一个好的哈希算法可以让碰撞产生得更少，查找速度越接近于O(1)，所以一个好的哈希算法非常重要。
哈希算法很多，说都说不完，不同的算法适应不同的场景，我知道的，传说中有一个哈希算法，来自魔兽世界（！！！！为了部落！！！！），号称暴雪哈希，该算法产生的哈希值完全无法预测，被称为&amp;ldquo;One-Way Hash&amp;rdquo;( A one-way hash is a an algorithm that is constructed in such a way that deriving the original string (set of strings, actually) is virtually impossible)。</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x04)---B&amp;#43;树</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing--0x04-----b</link>
      <pubDate>Sat, 31 Dec 2016 11:33:48 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing--0x04-----b</guid>
      <description>本篇较长较枯燥，请保持耐心看完。
前面两章介绍了一下倒排索引以及倒排索引字典的两种存储结构，分别是跳跃表和哈希表，本篇我们介绍另一种数据结构，他也被大量使用在信息检索领域，我在github上实现的搜索引擎的词典也是用的这个数据结构，它就是B+树。
首先，我们看看什么是树，树是程序设计中一个非常基础的数据结构，记得大学时候的数据结构课，链表，栈，队列，然后就是树了，虽然那时候想必大家都被前序遍历，中序遍历，后序遍历折腾过，不过树确实是一种非常有用的数据结构。
上一篇我们说过，表2的第一列首要解决的问题就是能快速找到对应的词，然后找到对应词的倒排列表，除了跳跃表和哈希表，B+树也能满足条件，B+树是B树的变种，我们B树我们就不看了，感兴趣的大家可以直接去google一下，我们主要讲的是B+树，下图就是一个3层的B+树，我画出来可能和大家搜出来的有点出入，但是没关系，关键B+树这种数据结构的思想大家了解了就行。
假设我们有一组数字 34，40，67，5，37，12，45，24，那么，把他们存成B+树就是下图这个样子。
我们很明显看到几个特点
 每个节点的大小为2
 非叶子层的最后一个节点的最后一个元素为NULL
 最底层的叶子节点是顺序排列的，这个例子是从小到大
 上面的内节点的每一个元素都指向的下一级节点中最大的一个数相等
  我尽量的把B+树说简单点，网上的资料也好，查书也好，看上去都挺复杂的，首先我们看看怎么建立这棵树，我尽量用图了，少一些文字也好理解一点，前方大量图预警。
首先，我们的数组是34，12，5，67，37，40，45，24
第一步，初始化B+树，是这样子的 这时候，啥也没有，但是占用了两个节点，标识为无的，表示这个元素无意义，标记为NULL表示无穷大
第二步，插入34这个元素，那么图变成这样子 我们看到，插入的过程是顺着指针一直走到叶子节点，发现叶子节点是空的，然后把元素插入到叶子节点的头部，然后返回上一级节点，将NULL后移，然后把第一个元素置为他的子节点的最大值，请记住这句话：置为他的子节点的最大值
第三步，接着插入第二个元素12 这个步骤复杂一点
 从根节点开始遍历，发现12小于根节点的某一个元素【在这里是第1个元素】，顺着指针往下走
 到达叶子节点，发现12小于叶子节点的某一个元素，说明可以放在这个叶子节点中，并且叶子节点还有一个空位置，那么直接把12按大小顺序插入到这个节点中
  第四步，然后是插入5 这一步更复杂一点，产生了分裂
 从根节点开始遍历，5小于34，顺着指针往下走，到达叶子节点
 到达叶子节点，发现5小于叶子节点的某一个元素，说明可以放在这个叶子节点中，但是，这个节点已经满了，那么，分裂出一个新的节点，将5放到老节点中，被挤走的元素顺移到新节点中
 返回上一级节点，由于第一个叶子节点的最大元素已经变成12了，所以将该节点的元素由34改成指向的叶子节点的最大元素12
 由于新生成了一个节点，将NULL这个元素指向新生成的节点
  第五步，接着我们插入67 这一步比较简单
 从根节点开始遍历，67小于NULL，顺着指针往下走，到达叶子节点
 到达叶子节点，发现67大于该节点的每一个元素，并且叶子节点有空位，直接插入即可
  第六步，我们插入37，插完这个后面的我就不写了，感兴趣可以自己画一下 这一步复杂了，这一步不仅分裂了，而且分裂了两次，并且层数增加了一层
 从根节点开始遍历，37小于NULL，顺着指针往下走，到达叶子节点
 到达叶子节点，37小于叶子节点中的67，表示可以插入到这个节点中，但是节点满了，我们按照第四步的操作，分裂节点。
 分裂完了以后，产生了一个[34,37]，一个[67,无]两个节点，往上走的时候，发现上一层的节点插入了37以后也满了，继续按照第四步分裂。
 分裂完了以后，发现上层没有节点了，那么就新建一个根节点当上层节点，按照分裂的步骤给根节点赋值。
  按照这六步，前5个元素就插入到B+树中了，后面的步骤您可以自己走一走，B+树基本的思想就是这样子的，可能我没有按照教科书上的做法来说，但这并不影响大家的理解，我相信看完了以后虽然你脑子里没有标准的算法步骤，但应该有个大致的轮廓了，只不过需要自己再仔细想想步骤。
总的来说，B+树的插入步骤无外乎以下几个步骤  每次都要从根节点开始
 比较大小，找到小于当前值的元素，顺着指针往下走，继续比较大小，一直到达叶子节点，那么这个叶子节点就是你要操作的节点了。</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x05)---文本相关性排序</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x05----wen-ben-xiang-guan-xing-pai-xu.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:48 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x05----wen-ben-xiang-guan-xing-pai-xu.html</guid>
      <description>https://segmentfault.com/a/
上面我们已经说过了一些倒排索引的东西，并且也知道了如何来实现一个倒排索引完成检索功能，那么检索完了以后如何排序呢，这一篇简单的说一下倒排索引的文本相关性排序，因为排序实在是太复杂了，我们这里就说说文本的相关性排序，而且是最简单的TD-IDF排序，之后有机会可以再说说整个搜索的排序算法有些什么。
文本相关性排序 首先明白几个概念：
 Term，分词以后最小的单位，比如用Golang写一个搜索引擎，分词以后就是用，golang，写，一个，搜索引擎，那么每一个词就是一个Term。
 TF(Term Frequency)，Term在文章中出现的频率，就是当前term在文章中出现的频率，就是term次数/总term数，比如上文中的搜索引擎这个term的TF就是1/5，TF越高那么这篇文章中的这个词就越重要。
 DF(Document Frequency)，文档频率，就是某个Term在总文档中出现的频率，比如总共有100个文档，其中搜索引擎这个term在10个文档中出现了，那么他的IDF就是5/100=0.5。
 IDF(Inverse Document Frequency)，逆文档频率，听名字就知道是和上面的DF是反的，用总文档数除以包含term的文档数，再求对数即可，上面的搜索引擎的IDF是log(100&amp;frasl;5)
  如何在一堆文章中找到包含关键词的文章，倒排索引技术已经帮我们解决了，只要分词分得准确，那么找文章没什么问题了。问题是找到一堆文章以后怎么进行排序，让最重要的文章排在最前面，这里介绍一下相关性排序。
TF-IDF相关性排序 上面我们看到TF和IDF的概念，TF明显作用就是表示一个term在文章中的重要程度，TF越高那么这个词在文章中的重要程度越明显，IDF呢，IDF主要用来描述term在整体文章中的重要程度（也就是区分程度），IDF越高，那么这个term的整体重要性越高，也就是区分度越大，越能体现这个term的重要性。
为什么用log呢？其实我个人觉得啊，用不用log其实区别没那么大，TF-IDF只是一种计算文本相关度的思想，并不是一个有严格证明的公式，所以用不用log区别不大，不过从信息论的角度看的话，妖人香农提出的信息量的公式就是logX的样子，值越大信息量就越大，正好可以套在我们这，IDF越大，信息量也越大。
 信息量是什么大家可以自己去百度，简单描述起来就是某一件事情发生的概率的，如果某件事情发生的概率是P，那么他的信息量就是 -logP，注意有个负号，比如中国队男子足球队和巴西队男子足球队打比赛，假设中国队赢的概率是 0.01（可能高估了），但如果巴西队赢了，根据公式算出来信息量几乎没有，因为谁都知道巴西会赢，但如果(我是说如果)最后中国队赢了，那么信息量算出来就是巨大的，肯定上各个头版了，这也和我们的直觉比较一致，在IDF中，就是用的这个公式，不过吧负号放里面去了，变成了log(1/P)，而P就是DF，term在总文档中出现的频率。
 TF和IDF合起来表示这个term的相关性，就是把这两个值乘起来。
为什么要把这两个概念合起来呢，第一个TF已经可以描述term的重要性了，为什么还要用IDF呢，主要可以解决两个问题。
 去掉高频词的噪音，既然IDF可以简单理解为term的信息量，那么它主要就是为了去掉噪声，也就是去掉那些个信息量很小的term的影响。比如的这个词，它的TF非常高，但实际上没什么含义，但是你一算他的IDF，基本是0，所以如果用TF*IDF的话，结果还是0，可以比较有效的去掉这类通用词的干扰。
 同时IDF还可以更好的区分重要的词，如果一个term的IDF越高，证明带这个term的文章的更加能用这个term来表示，这个很好理解，如果一个term只在某一篇文章中出现，那么这个词更能代表这篇文章的内容。
  最后，多个term联合检索的时候，他们的相关性就是每一个term的TF-IDF加起来，
OK，TF-IDF就是这些了，实现的时候，如果是最初做全量索引的话，由于整体文档数是已知的，那每个term的TF-IDF一般是建立索引的时候就把它算好了，检索的时候按这个一排序就行了，我实现的时候由于没有全量索引的概念，所以只是在每添加一个文档的时候算好这个文档的TF存起来，检索的时候通过term倒排召回的文档数来确定IDF的值，实时算出TF-IDF的，如果是非常巨大的文档数量，那么实时算还是很吃亏的，所以说全量索引还是非常必要的，只是我这没有完整实现全量索引建立而已，但后面接下来我会说说全量索引如何建立。
词距 除了TF-IDF来进行相关性排序以外，还有一些其他的文本因素也可以用在排序上，一是term的距离，也就是词距，如果检索关键词是小米手机，那么明显的，如果一篇文章中这两个term(小米，手机)挨在一起，比如小米手机是一款很热门的手机和手机应用中有很多关于健康的文章，比如吃小米有什么好处这两篇文档，明显第一篇的相关度比第二篇要高。
所以，为了保持词距的信息，我们在存储倒排的时候还需要将每个term的位置信息保存下来，检索的时候用过这些个位置信息计算各个词直接的词距，从而和TF-IDF合在一起来表述文本相关性。
位置信息 同时，除了词距以外，还有一个因素也影响相关度的排序，那就是term的位置，这个也很好理解，如果在标题，摘要命中的话明显应该比在正文中命中term的权重高，一般这种情况是把标题，摘要命中的TD-IDF乘以一个系数来扩大影响，从而影响最后的相关度计算结果。
其他模型 除了直接使用TF-IDF以外，现在还有很多其他的文本相关性的排序模型，比如BM25这种以概率为基础的排序模型，这里就不展开了，如果大家有兴趣，写完这些篇以后可以专门写几篇怎么排序的，包括文本排序，以及文本之后的重要性排序啊，怎么离线利用机器学习计算文档重要性来排序之类的，在说排序的时候我们会说一下如何将这些个所有的东西【文本相关性，词距，位置，重要性，销量，点击等】合起来进行打分
下面一篇文章会再讲讲倒排索引存储的一些我没有实现的东西，比如索引压缩之类的，然后会讲讲如何建立倒排，如果进行增量添加文档，如何进行索引合并。
最后，欢迎大家扫描一下下面的微信公众号订阅，首先会在这里发出来：）</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x06)---索引构建</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x06----suo-yin-gou-jian.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:48 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x06----suo-yin-gou-jian.html</guid>
      <description>https://segmentfault.com/a/
不知不觉写到第七篇了，按这个节奏，估计得写到15到20篇左右才能写完，希望自己能坚持下去，之前写代码的时候很多东西并没有想得那么细致，现在每写一篇文章还要查一些资料，确保文章的准确性，也相当于自己复习了一下吧，呵呵。
先说一下，关于倒排文件，其实还有很多东西没有讲，到后面再统一补充一下吧，主要是倒排文件的压缩技术，这一部分因为目前的存储空间不管是硬盘还是内存都是很大的，所以压缩技术用得不是很多了。
今天我们来讲讲倒排索引的构建。
之前，我们了解到了，倒排索引在系统中是存成下图这个样子
上面的B+树是一个文件，下面的倒排链是一个文件，那么，如何来构建这两个文件呢，本章我会说说一般的常规构建方法，然后说一下我是怎么构建的。
一般情况下，搜索引擎默认会认为索引是不会有太大的变化的，所以把索引分为全量索引和增量索引两部分，全量索引一般是以天甚至是周，月为单位构建的，构建完了以后就导入到引擎中进行检索，而增量索引是实时的进入搜索引擎的，很多就是保存在内存中，搜索的时候分别从全量索引和增量索引中检索数据，然后把两部分数据合并起来返回给请求方，所以增量索引不是我们这一篇的主要内容，在最后我的索引构建部分我会说一下我的增量索引构建方式。现在先看看全量索引。
全量索引构建一般有以下两种方式
一次性构建索引 一种是一次性的构建索引，这种构建方法是全量扫描所有文档，然后把所有的索引存储到内存中，直到所有文档扫描完毕，索引在内存中就构建完了，这时再一次性的写入硬盘中。大概步骤如下：
 初始化一个空map ，map的key用来保存term，map的value是一个链表，用来保存docid链
 设置docid的值为0
 读取一个文档内容，将文档编号设置成docid
 对文档进行切词操作，得到这个文档的所有term(t1,t2,t3&amp;hellip;)
 将所有的&amp;lt;term,docid&amp;gt;键值对的term插入到map的key中，docid追加到map的value中
 docid加1
 如果还有文档未读取，返回第三步，否则继续
 遍历map中的&amp;lt;key,value&amp;gt;，将value写入倒排文件中，并记录此value在文件中的偏移offset，然后将&amp;lt;key,offset&amp;gt;写入B+树中
 索引构建完毕
  用图来表示就是下面几个步骤
如果用伪代码来表示的话就是这样
//初始化ivt的map 和 docid编号 var ivt map[string][]int var docid int = 0 //依次读取文件的每一行数据 for content := range DocumentsFileContents{ terms := segmenter.Cut(content) // 切词 for _,term := range terms{ if _,ok:=ivt[term];!ok{ ivt[term]=[]int{docid} }else{ ivt[term]=append(ivt[term],docid) } docid++ } //初始化一棵B+树,字典 bt:=InitBTree(&amp;quot;.</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x07)---正排索引</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x07----zheng-pai-suo-yin.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:47 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x07----zheng-pai-suo-yin.html</guid>
      <description>https://segmentfault.com/a/
最近各种技术盛会太多，朋友圈各种刷屏，有厂商发的各种广告，有讲师发的各种自拍，各种参会的朋友们各种自拍，好不热闹，不知道你的朋友圈是不是也是这样啊，去年还没这么多技术会议，今年感觉爆发了，呵呵，真是一个互联网技术的好时代，而且还有各种撕B可看，真想八一八，怕得罪人，我们这种码农还是专注技术专注写代码吧。
你有什么想了解的也可以给我留言哈，欢迎交流，我的工作之前主要做的是搜索的，也做推荐和广告，这部分的东西可能写得多点，对了，嵌入式领域也行（跨得有点大，这个嵌入式不是iOS和Android，是真的嵌入式），没什么高端背景，也不是BAT这种大厂的，就是一小公司写代码的，所以有很多东西还是不懂，你要是和我交流了发现我答不上来很正常啊，人艰不拆啊。。
本篇也比较长，但是干货不多，建议上厕所的时候看，或者在地铁一边听歌一边看。
前面几篇，基本上把倒排索引的数据结构给讲完了，并且简单的说了一下排序，然后说了一下倒排索引的构建。这一篇主要写一下正排索引以及倒排和正排怎么配合起来形成一个完整的字段索引。
正排索引 正排索引，也叫前向索引，和倒排索引（也叫反向索引）是相对的，正排索引相对倒排来说简单多了，第二篇文章的时候有下面两个表格（表1和表2）
这个是表1
文档编号 文档内容
1 这是一个Go语言实现的搜索引擎 2 PHP是世界上最好的语言 3 Linux是C语言和汇编语言实现的 4 谷歌是一个世界上最好的搜索引擎公司
这个是表2
关键词 文档编号
Go 1 语言 1，2，3 实现 1，3 搜索引擎 1，4 PHP 2 世界 2，4 最好 2，4 汇编 3 公司 4
我们之前一直在说作为倒排索引的表2，对于表1，我们认为是数据的详情(detail)信息，最后用来做数据内容展示的，如果是放在一个只支持全文搜索的搜索引擎中的话，那确实表1只是用来做最后的数据展示，但是如果我们的搜索引擎还想要一些复杂的功能，那么表1就是一个正排索引，如果我们的搜索引擎同时支持倒排索引和正排索引，我们可以简单的认为这是一个数据库系统（当然，和真正的数据库还差得远啊）。
首先，我们看什么情况下要使用正排索引 很明显，如果倒排索引满足不了搜索要求的时候，就需要引入正排索引，比如一个电商的搜索引擎，那么正排索引就是必须的了，假如我们有以下几个商品需要上架：
商品编号 商品标题 发布时间 价格 品牌
10001 锤子手机T9 2026-06-06 5000 锤子 10002 小米手机10 2020-02-02 1999 小米 10003 华为手机P20 2022-12-12 3999 华为
搜索的时候我们可能需要搜索价格在一个区间的手机，那么仅仅用全文倒排索引就比较难完成任务了，而且我们在使用电商的搜索引擎的时候，经常会在搜索结果的上方看到一些汇总的信息【比如品牌，型号，价格汇总】，这一部分的东西也是通过正排索引来实现的，像下面这个图
所以说，如果我们的搜索需求不仅仅是进行关键词的匹配，还需要进行一些过滤操作（比如价格区间的过滤），汇总操作（比如结果集中每种品牌数量的统计），那么就必须引入正排索引了。
第二，我们看看如何实现一个正排索引 实现正排索引有两种方式：
一种还是基于倒排索引，之前的倒排索引不是通过B+树构建的么，B+树天然的带排序功能，所以是可以进行范围查找的，比如上面那个表格，我们要搜索的关键词为手机，价格区间在1500–4000之间。
 我们把价格字段和商品标题字段分别建立一个倒排。</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x08)---索引的段</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x08----suo-yin-de-duan.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:40 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x08----suo-yin-de-duan.html</guid>
      <description>https://segmentfault.com/a/
我觉得这个标题应该改改了，我写下来其实是告诉大家怎么写一个搜索引擎，并没有涉及太多的Golang的东西，我觉得这样也挺好，熟悉了原理，用什么实现其实并不重要了，而且说说原理比说代码更实在。
之前已经说了底层的数据结构了，包括倒排和正排索引。今天我们上一层，来说说索引的字段和段。
字段这个上一篇已经介绍过了，字段的概念实际上是搜索引擎索引中我们能看到的最底层的东西，也是对外暴露的最底层的概念，在字段之下是倒排和正排索引，这两项其实对用户是封装起来了，我们可以认为每个字段对应一个正排和一个倒排，而实际上也确实是这样的。
在字段之上就是我们这一篇主要说的段了，段这个概念并不是搜索引擎特有的，也不是必须的，是我这个项目新增出来的，当然，也不是我原创，很多搜索引擎的引擎系统都有这个概念。
所谓段，就是最基本的检索系统，一个段包含所有字段，包含一部分连续的文档集合，能够进行完整的检索，可以把它当成一个检索系统最基本单位。
这么说可能还是有点抽象，我们打个比方，在数据库中，一行数据是最基本的单位，对应搜索引擎中的是一个文档，而表是所有文档的集合，对应搜索引擎中是一份索引，而段就是一部分表，它包含一部分文档的内容，可以对这一部分文档进行检索，多个段合并起来就是一份完整的索引。
为什么要有段这个概念呢？  如果一个搜索引擎的数据再建好索引以后并不变化，那么完全没有必要使用段，直接在建立全量索引的时候把数据都建好就行了
 如果有增量数据，并且增量数据是不断进入系统的话，那么段的概念就有必要了，新增的数据首先在内存中进行保存，然后周期性的生成一个段，持久化到磁盘中提供检索操作。
 段还有一个好处就是当系统是一个分布式的系统的时候，进行索引同步的时候，因为各个段持久化以后就不会变化了，只需要把段拷贝到各个机器，就可以提供检索服务了，不需要在各个机器上重建索引。
 一个段损坏了，并不影响其他段的检索，只需要从其他机器上将这个段拷贝过来就能正常检索了，如果只有一个索引的话，一旦索引坏了，就无法提供检索服务了，需要等把正确索引拷贝过来才行。
  一个段都存一些什么信息呢？ 一个段包含几个文件
 indexname_{segementNumber}.meta 这里是段的元信息，包括段中字段的名称，类型，也包括段的文档的起始和终止编号。
 indexname_{segementNumber}.bt 这里是段的倒排索引的字典文件
 indexname_{segementNumber}.idx 这里是段的所有字段的倒排文件
 indexname_{segementNumber}.pfl 这里是段的所有数字正排文件的数据，同时也包含字符串类型数据的位置信息
 indexname_{segementNumber}.dtl 这里是段的字符串类型数据的详情数据
  上面的indexname是这个索引的名称，相当于数据库中的表名，segmentNumber是段编号，这个编号是系统生成的。
多个段合在一起就是一个完整的索引，检索的时候实际上是每个段单独检索，然后把数据合并起来就是最后的结果集了。
段的构建 下面我们一个一个来说说这些个文件，看看一堆正排和一堆倒排如何构成一个段的。
一个真正意义上的段的构建由以下几个步骤来构建，我们以一个实际的例子来说明一下段的构建，比如我们现在索引结构是这样，这个索引包括三个字段，分别是姓名(字符串)，年龄(数字)，自我介绍(带分词的字符串)，那么构建段和索引的时候步骤是这样的
1.前期准备 首先新建一个段需要先初始化一个段，在初始化段的时候我们实际上已经知道这个段包含哪些字段，每个字段的类型。
 初始化一个段信息，包含段所包含的字段信息和类型，在这里就是包含姓名(字符串【正排和倒排】)，年龄(数字【正排】)，自我介绍(带分词的字符串【正排和倒排】)。
 给段一个编号，比如1000。
 准备开始接收数据。
  2.建立内存中的段 内存中的段是构建段的第一步，以上述的字段信息为例，我们会在内存中建立以下几个数据结构，在这里我都是使用语言自动的原始数据结构
 姓名需要建立倒排索引，所以建立一个map&amp;lt;string,list&amp;gt;，key是姓名，value是docid，姓名也要建立正排索引，所以建立一个StringArray[]，保存每条数据的姓名的详情。
 年龄需要建立正排索引，所以建立一个IntegerArray[]，保存每条数据的年龄的详情。
 自我介绍需要建立倒排索引，所以建立一个map&amp;lt;string,list&amp;gt;，key是自我介绍的分词的term，value是docid，自我介绍也要建立正排索引，所以建立一个StringArray[]，保存每条数据的自我介绍的详情。
  当新增一条数据的时候{&amp;quot;name&amp;quot;:&amp;quot;张三&amp;quot;,&amp;quot;age&amp;quot;:18,&amp;quot;introduce&amp;quot;:&amp;quot;我喜欢跑步&amp;quot;}，首先我们给他一个docid【假如是0】，然后我们把数据分别存放到上面的5个数据结构中，如果再来一条数据{&amp;quot;name&amp;quot;:&amp;quot;李四&amp;quot;,&amp;quot;age&amp;quot;:28,&amp;quot;introduce&amp;quot;:&amp;quot;我喜欢唱歌&amp;quot;}，我们给他一个docid【假如是1】，那么数据就变成了下图的样子
3.将数据结构持久化到磁盘中 这样，随着数据的不停导入，内存中的数据结构不断变化，内存段的数据也越来越大，当达到一定阈值的时候（这部分策略以后会说，我把这部分策略放到了引擎层，由引擎来决定什么时候进行段的持久化），我们将把数据持久化到磁盘中。
进行持久化的过程中
 如果是map的数据结构，我们将遍历整个map，首先将value追加写到.idx文件中，然后把key建立B+树，value是刚刚写入的idx文件的偏移位置。
 如果是IntegerArray，我们遍历整个数组，然后把数据写入到pfl文件中，每个数据占用8个字节。</description>
    </item>
    
    <item>
      <title>用Golang写一个搜索引擎(0x0B)---第一部分结束</title>
      <link>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x0b----di-yi-bu-fen-jie-shu.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:36 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yong-golangxie-yi-ge-sou-suo-yin-qing-0x0b----di-yi-bu-fen-jie-shu.html</guid>
      <description>这一篇算给这一个系列告一个小的段落，之前开始写这些文章的时候，只是想把自己最近用Golang写的这个搜索引擎说一说，准备了大概3，4篇的量，但是一写下来，发现有点收不住，写到后面其实和Golang没什么关系了，主要在写搜索引擎的架构和一些数据结构了，我觉得这比写代码注释有用吧，而且通过这样写下来，我自己对这些个数据结构的理解也更深了。
一个月的时间，写了14篇了，虽然14篇文字不足以说明一个搜索引擎的实现，但我觉得基本上一些重要的东西我都说了，搜索引擎本身原理上其实比较简单，并且我们并没有涉及搜索引擎爬虫的部分，所以说起来并不是很复杂，复杂是复杂在外围一些算法上的东西，比如分词，比如排序之类的。
来看看我们都说了些啥  开了个头以后，先说了一下搜索引擎的基本概念，包括docid的概念，以及整个搜索引擎的分层情况
 然后说了倒排索引技术，也是搜索引擎最最底层和核心的概念了。
 倒排索引分成词典和倒排文件两部分，接着说了一下倒排索引的词典的几种实现方式，包括哈希表和B+树的方式，并且简单介绍了一下跳表。
 倒排索引技术说完了以后，按步骤的说了倒排索引的构建，包括全量和增量的构建，以及各种构建方式，最后说了一下我的构建方法。
 倒排的原理，数据结构，构建方式介绍完了以后花了一篇介绍了一下正排索引。
 倒排和正排两个基础数据结构说完了以后说了索引的分段策略，分段是为了更灵活的使用索引而出现的一种技术。
 段之后就是索引层了，索引层先说了数据如何进行增删改。
 最后介绍了一下数据的检索，包括一些求交集，求并集的过程，这一篇实际上就是索引层之上的引擎层做的事了。
  然后除了上面这些，穿插的说了一下搜索引擎的一些外围的技术，包括文本相关性，排序，机器学习和长尾词的一些问题。
照这样，第一部分应该差不多可以结束了，一个单机版的搜索引擎只需要上面一些东西就可以完整的实现了，也欢迎大家去我的github上看看，目前开源出来的就是一个简单的单机版的搜索引擎了，主要的结构如下，很简单的，欢迎提交bug，由于是自己的玩具项目，没有写单元测试，代码中的_test.go文件都是功能测试。
但是，这个系列也远没结束，关于搜索引擎还有好多可以说的，并且索引分片和分布式都还没开始呢，只是第一部分的单机版的结束了，后面会用一个系列说一下搜索引擎的分布式实现，当然代码也会跟着更新。
后面的文章更新还是会围着搜索，推荐和广告这三个方面来说，我觉得这三个其实是一体的，用的技术也差不多，算法上三个看上去有区别，其实底层也差不太多，特别是广告，简直就是推荐+搜索的组合，所以文章在架构和算法上也都会涉及到，当然也会有比较扯淡的文章，比如今天这篇。
最后，既然是Golang写的搜索引擎，那么我们来聊聊Golang吧。 用了快一年的Golang了，我是从C/C++转过来的，之前近10年都在和C++打交道，除了C/C++，用过python，objective-C，C#，Lua，Erlang，很抱歉，没有用过世界上最好的语言PHP，也没有用过世界上最火的语言JAVA（用来写hadoop作业应该不算用JAVA吧），我个人觉得Golang设计出来完全就是一门工程性的语言，工程性非常强，确实很适合后台类型的开发。
这里不做语言之争，仅写写我的一些感受吧，总的来说，我个人觉得Golang非常棒。
我们来先说好的  开发效率和之前的c比起来不知道高了多少倍，基础数据结构比较全，其实主要就是map啦。
 更舒服的是感觉用起来和c差别不大，有指针哦，这点对于一个C程序员来说很重要哦。
 把接口用活就能写出好的Golang代码，设计模式那一套不用套来套去了，当然，设计模式那一套思想我觉得还是很有用的。
 error返回值，这点可能个人爱好吧，我觉得挺好，不用去捕获什么异常了，特别JAVA那种（虽然没写过，但JAVA代码还是看过不少的）一个异常可以像盗梦空间一样抛出好几层简直就是噩梦，出错了就出错了呗，返回错误就行，还来个什么异常做甚。
 协程和管道就不说了，各种讨论已经很多了。
 高阶函数，闭包随便搞，很多新的函数式编程思想也可以比较舒服的用在golang中
 调试也不错，可以用GDB，然后还有个性能测试工具也挺好，基本上这两个再加上printf就能搞定几乎所有的bug和性能瓶颈了。
  坏的呢？  垃圾回收应该算是个优点，让你不用关心new了的对象什么时候释放，但作为一个老程序员，有些时候（其实是很多时候）你并不知道你的程序的内存空间是什么样子的，特别是一个搜索引擎的开发，本来就吃内存，你还不确定内存用了多少，用在了什么地方，还是很不爽的，不如自己new自己delete来得直接，虽然自己管理有可能有内存泄露，那改bug就好了，改到不泄露呗。当然，你可以说出一万个有自动垃圾回收的语言的好处，但我也能说出一个自己管理内存的好处：自由。
 没有泛型，没有泛型，没有泛型！无力吐槽。据说也不准备加。
 不支持动态加载.so，这个其实很重要，特别是不能停机的服务，比如搜索引擎，如果可以动态加载.so，那修改算法，修改策略，分分钟上线而不用停服，不过好像1.6支持了？我没关注过不知道，我现在用的还是1.4.2
  总的来说，我还是非常非常推荐Golang的，下次有时间试试Rust，看看如何，不过我个人不太看好Rust，现在编程语言这么多，还有PHP这种王牌语言，一个崭新的语言后面没有一个强大的公司支撑的话，最后不管多牛逼也只能呵呵。
最后，我的这个开源项目(https://github.com/wyh267/FalconEngine)，我会坚持写下去，变成一个分布式的搜索引擎，希望在性能上能达到ES的水平吧，也欢迎大家关注，之前是为了熟悉搜索引擎本身数据结构，所以自己撸了很多基础代码，后面为了能让更多人用起来，也为了稳定性我会引入一些开源的组件而不是自己造轮子了。
想看之前所有文章，可以关注公众号，然后点击公众号的菜单即可：）或者直接看SF的专栏也行。
欢迎关注我的公众号，文章会在这里首先发出来：）扫描或者搜索微信号XJJ267或者搜索中文西加加语言就行</description>
    </item>
    
    <item>
      <title>一步一步教你写BT种子嗅探器之一---原理篇</title>
      <link>https://yushuangqi.com/blog/2016/yi-bu-yi-bu-jiao-ni-xie-btchong-zi-xiu-tan-qi-zhi-yi----yuan-li-pian.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:14 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yi-bu-yi-bu-jiao-ni-xie-btchong-zi-xiu-tan-qi-zhi-yi----yuan-li-pian.html</guid>
      <description>之前看到 lantern 这个十分火的翻墙工具，其利用了P2P的思想，就想了解一下P2P相关的协议。看了下最流行的BT协议官方文档，就产生了实现BT协议的想法，顺便根据协议实现了一个BT种子嗅探器。
也有人将BT种子嗅探器称为BT种子爬虫，个人觉得其行为特性和传统的web爬虫相差较大，反而和嗅探器很类似，因此暂且称之为BT种子嗅探器吧。
接下来将写一系列文章来介绍其原理和具体实现方式。这篇文章先提纲挈领，介绍其工作原理，以对全局有一个把握。后序的文章再介绍具体细节。
背景知识 在讲原理之前首先你得具备BitTorrent(简称BT)协议的一些基本知识，以便于理解接下来要讲的嗅探器。BT协议其实是一个协议簇，BEP-3 是其基本协议内容，其他的大部分都是围绕这个来进行扩展或补充。要想从BT网络中下载一个资源，必须具备以下部分：
 种子文件（也就是我们常说的种子，后缀是 .torrent，本质上是一个由bencode编码的文本文件，其把资源分成很多虚拟块，并记录每个块的hash值，另外上面还记录着其他信息，比如文件大小、名字、Tracker服务器等）
 BT客户端（需要有专门解析BT协议的程序，这样才能下载，比如迅雷，电驴）
 Tracker服务器 （记录着peer和种子相关信息，起着中心调控的作用）
  下载资源的时候，客户端首先根据bencode（bencode是BT协议中的编码方式）解码种子文件，得到Tracker服务器的地址和资源信息，通过和Tracker服务器沟通得到其他已经下载该资源的peers信息（其他已经拥有该资源的客户端或者发布该资源的人），然后再和这些peers沟通得到自己想要的部分，即互通有无。由于把文件分成很多块来同时从不同的地方下载，这也就是为什么BT通常下载快的原因。
DHT协议 通过上面我们知道，Tracker服务器在资源下载的过程中起着至关重要的作用，只有通过它我们才能得到其他peers的信息，才能够下载，但这同时也成了BT协议的一个弱点，如果Tracker服务器挂掉了或者被封被屏蔽，整个网络也就瘫痪了。由于一些资源都是有版权的，还有一些资源是限制级的，比如色情资源，Tracker服务器很容易被迫关闭或被墙。后来聪明的人类发明了另外一种协议，就是 Distributed hash table, 简称DHT，这个协议就是用来弥补这个弱点的。
BT协议簇中的DHT协议 是基于 Kademlia协议 建立的，其基本思想很好理解。DHT 由很多节点组成，每个节点保存一张表，表里边记录着自己的好友节点。当你向一个节点A查询另外一个节点B的信息的时候，A就会查询自己的好友表，如果里边包含B，那么A就返回B的信息，否则A就返回距离B距离最近的k个节点。然后你再向这k个节点再次查询B的信息，这样循环一直到查询到B的信息，查询到B的信息后你应该向之前所有查询过的节点发个通知，告诉他们，你有B的信息。
举个例子，比如我现在想要Angelababy的微信号（额…我要干嘛），我就从自己的微信好友中挑出k个最可能认识她的人，然后依次问他们有没有Angelababy的微信号，假如其中一个认识，那么他就会给我Angelababy的微信号，我也就不继续问其他人了。假如他不认识，他就给我推荐k个他微信好友中最有可能认识Angelababy的k个人，然后我再继续这k个人，就这样循环一直到我问到为止。OK，现在我已经得到了Angelababy的微信号，我就会告诉之前所有我问过的人，我有Angelababy的微信号。
当客户端下载资源的时候，他会利用上述方式查找peers信息，这样每个人都充当了Tracker的作用，也就解决了上面那个问题。
嗅探器原理 终于到核心部分了。
BT种子嗅探器就是利用了DHT协议得到peer信息后会向他之前查询过的节点发送通知这一点，这就是嗅探器的核心。
剩下的工作就是我们要让更多的节点发给我们通知。那么如何让更多的节点发给我们通知呢？
 我们要不断的查询自己的好友节点表，并对返回回来的节点进行查询，这样才会有更多的人认识我们
 别人向我们查询Target的时候，我们要伪装成Target的好友，返回结果里边包括自己，这样会有更多被查询、收到通知的机会
  这就是BT种子嗅探器的原理，简单吧 :)
种子下载器 在BT网络中，通过上述原理收到信息并不是种子，而是发送消息者的ip和port、种子infohash（可以理解为种子的id）。我们如果想要得到种子的话，还需要做一番工作。这里涉及到另外一个非常重要的协议 BEP-09，BEP-09规定了如何通过种子infohash得到种子。
这里不铺开讲，仅说下大致过程。首先同我们收到的消息里边的 ip:port 建立TCP连接，然后发送握手消息，并告知对方自己支持BEP-09协议，然后向对方请求种子的信息，收到对方返回的种子信息后，依次或同时请求每一个块。最有所有块收集完后，对其进行拼接并通过sha1算法计算其infohash，如果和我们请求的infohash值相同则保存起来，否则丢掉。
应用 这样你可以得到非常多的种子信息，你可以对其进行索引建立自己的BT种子搜索引擎，建立自己的海盗湾。但你需要注意版权问题和色情资源问题。
最后 https://github.com/shiyanhui/dht 这个是Go实现的一个BT种子嗅探器，你可以参照一下其具体实现，喜欢这篇文章的话就到github上给个Star呗。
http://bthub.io 是基于上面这个嗅探器写的一个BT种子搜索引擎。
有任何问题可以在这里提问：https://github.com/shiyanhui/&amp;hellip;
关注我的公众号，及时获得下一篇推送。</description>
    </item>
    
    <item>
      <title>一步一步教你写BT种子嗅探器之二---DHT篇</title>
      <link>https://yushuangqi.com/blog/2016/yi-bu-yi-bu-jiao-ni-xie-btchong-zi-xiu-tan-qi-zhi-er----dhtpian.html</link>
      <pubDate>Sat, 31 Dec 2016 11:33:14 +0800</pubDate>
      <author>ysqi@yushuangqi.com (虞双齐)</author>
      <guid>https://yushuangqi.com/blog/2016/yi-bu-yi-bu-jiao-ni-xie-btchong-zi-xiu-tan-qi-zhi-er----dhtpian.html</guid>
      <description>之前写了原理篇，在原理篇里简单的介绍了一下DHT，但是还不够详细。今天我们就专门详细的讲一下嗅探器的核心-DHT，这里默认原理篇你已经读了。
背景知识 DHT全称 Distributed Hash Table，中文翻译过来就是分布式哈希表。它是一种去中心化的分布式系统，特点主要有自动去中心化，强大的容错能力，支持扩展。另外它规定了自己的架构，包括keyspace和overlay network（覆盖网络）两部分。但是他没有规定具体的算法细节，所以出现了很多不同的实现方式，比如Chord，Pastry，Kademlia等。BitTorrent中的DHT是基于Kademlia的一种变形，它的官方名称叫做 Mainline DHT。
DHT人如其名，把它看成一个整体，从远处看它，它就是一张哈希表，只不过这张表是分布式的，存在于很多机器上。它同时支持set(key, val)，get(key)操作。DHT可以用于很多方面，比如分布式文件系统，DNS，即时消息(IM)，以及我们最熟悉的点对点文件共享（比如BT协议）等。
下面我们提到的DHT默认都是Mainline DHT，例子都是用伪代码来表示。读下面段落的时候要时刻记着，DHT是一个哈希表。
Mainline DHT Mainline DHT遵循DHT的架构，下面我们分别从Keyspace和Overlay network两方面具体说明。
Keyspace keyspace主要是关于key的一些规定。
Mainline dht里边的key长度为160bit，注意是bit，不是byte。在常见的编译型编程语言中，最长的整型也才是64bit，所以用整型是表示不了key的，我们得想其他的方式。我们可以用数组方式表示它，数组类型你可以选用长度不同的整型，比如int8，int16，int32等。这里为了下边方便计算，我们采用长度为20的byte数组来表示。
在mainline dht中，key之间唯一的一种计算是xor，即异或（还记得异或的知识吧？）。我们的key是用长度为20的byte数组来表示，因此我们应该从前往后依次计算两个key的相对应的byte的异或值，最终结果得到的是另外一个长度为20的byte数组。算法如下：
​for i = 0; i &amp;lt; 20; i++ { ​ result[i] = key1[i] ^ key2[i]; ​}  读到这里，你是不是要问xor有啥用？还记得原理篇中DHT的工作方式吗？
xor是为了找到好友表中离key最近的k个节点，什么样的节点最近？就是好友中每个节点和key相异或，得到的结果越小就越近。这里又衍生另外一个问题，byte数组之间怎么比较大小？很简单，从前往后，依次比较每一个byte的大小即可。
在Mainline DHT中，我们用160bit的key来代表每个节点和每个资源的ID，我们查找节点或者查找资源的时候实际上就是查找他们的ID。回想一下，这是不是很哈希表? :)
另外聪明的你可能又该问了，我们怎么样知道每个节点或者每个资源的ID是多少？在Mainline DHT中，节点的ID一般是随机生成的，而资源的ID是用sha1算法加密资源的内容后得到的。
OK，关于key就这么多，代码实现你可以查考这里。
Overlay network Overlay network主要是关于DHT内部节点是怎么存储数据的，不同节点之间又是怎样通信的。
首先我们回顾一下原理篇中DHT的工作方式:
 DHT 由很多节点组成，每个节点保存一张表，表里边记录着自己的好友节点。当你向一个节点A查询另外一个节点B的信息的时候，A就会查询自己的好友表，如果里边包含B，那么A就返回B的信息，否则A就返回距离B距离最近的k个节点。然后你再向这k个节点再次查询B的信息，这样循环一直到查询到B的信息，查询到B的信息后你应该向之前所有查询过的节点发个通知，告诉他们，你有B的信息。
 整个DHT是一个哈希表，它把自己的数据化整为零分散在不同的节点里。OK，现在我们看下，一个节点内部是用什么样的数据结构存储数据的。
节点内部数据存储 - Routing Table 用什么样的数据结构得看支持什么样的操作，还得看各种操作的频繁程度。从上面工作方式我们知道，操作主要有两个：
 在我（注意：“我”是一个节点）的好友节点中查询离一个key最近的k个节点（在Mainline DHT中，k=8），程度为频繁
 把一个节点保存起来，也就是插入操作，程度为频繁</description>
    </item>
    
  </channel>
</rss>